# Multi-Arm_Bandits_Thompson_Sampling
An exploration of solutions to multi-armed bandits using Thompson Sampling. 
