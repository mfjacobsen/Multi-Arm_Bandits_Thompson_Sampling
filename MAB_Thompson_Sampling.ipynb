{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.special import gamma\n",
    "import os\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors\n",
    "from numba import njit, prange\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "NUM_ALGO = 2\n",
    "MAX_T = 10000000\n",
    "MAX_DF = 10000\n",
    "NUM_QUANTILES = 99999\n",
    "LIMIT = 100000000\n",
    "\n",
    "# Precomputed values\n",
    "sqrts = np.sqrt(np.arange(MAX_T))\n",
    "\n",
    "# Load or compute sqare roots and quantiles\n",
    "sqrts_path = f'tables/first_{MAX_T}_sqrts.npy'\n",
    "n_quantiles_path = f'tables/n_quantiles_q{NUM_QUANTILES}.npy'\n",
    "t_quantiles_path = f'tables/t_quantiles_df{MAX_DF}_q{NUM_QUANTILES}.npy'\n",
    "\n",
    "# Ensure the 'data' directory exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Computes square roots\n",
    "if not Path(sqrts_path).exists():\n",
    "    sqrts = np.sqrt(np.arange(MAX_T))\n",
    "    np.save(sqrts_path, sqrts)\n",
    "\n",
    "# Computes normal and t distribution quantiles\n",
    "if not Path(n_quantiles_path).exists() or not Path(t_quantiles_path).exists():\n",
    "    \n",
    "    # Possible quantiles for Thompson sampling\n",
    "    quantiles = np.linspace(0.00001, 0.99999, NUM_QUANTILES).round(5)\n",
    "\n",
    "    # Computes quantiles for normal and t distributions up to MAX_DF\n",
    "    # after which normal approximation is used\n",
    "    n_quantiles = stats.norm().ppf(quantiles)\n",
    "    t_quantiles = np.array(\n",
    "        [stats.t(df).ppf(quantiles) for df in range(1, MAX_DF + 1)], \n",
    "                  dtype=np.float32)\n",
    "\n",
    "    # Saves the quantile tables\n",
    "    np.save(n_quantiles_path, n_quantiles)\n",
    "    np.save(t_quantiles_path, t_quantiles)\n",
    "\n",
    "# Loads quantile tables and square roots\n",
    "n_quantiles = np.load(n_quantiles_path)\n",
    "t_quantiles = np.load(t_quantiles_path)\n",
    "sqrts = np.load(sqrts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A numba implementation for np.random.choice using the CDF of probabilites\n",
    "@njit\n",
    "def weighted_choice(probabilities, size):\n",
    "    \"\"\"A numba implementation for np.random.choice using the CDF of probabilites\n",
    "\n",
    "    Args:\n",
    "        probabilities (np.array): An array of probabilities corresponding to the\n",
    "         probability of choosing that integer index. Should sum to 1.\n",
    "        size (int): The number of samples to choose from the probability vector\n",
    "\n",
    "    Returns:\n",
    "        np.array: A vector of length (size) of integers chosen with the given \n",
    "        probabilites\n",
    "    \"\"\"\n",
    "    cumulative_sum = np.cumsum(probabilities)\n",
    "    choices = np.searchsorted(cumulative_sum, np.random.rand(size))\n",
    "    return choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-determines rewards for each arm \n",
    "@njit\n",
    "def compute_rewards(k, R, T):\n",
    "    \"\"\"Pre-computes rewards for each arm of the bandit at round t\n",
    "\n",
    "    Args:\n",
    "        k (int): The number of bandit arms.\n",
    "        R (int): The range of reward.\n",
    "        T (int): The number of rounds in the game.\n",
    "\n",
    "    Returns:\n",
    "        numpy vector: deltas : A length k vector containg the difference in mean \n",
    "        of each arm from the arm wih the highest mean.\n",
    "        numpy matrix: arm_rewards: A k x T matrix that holds the rewards for \n",
    "        arm k at round T\n",
    "    \"\"\"\n",
    "\n",
    "    # Randomizes reward probability for each arm\n",
    "    p_vectors = np.random.dirichlet(np.ones(R), size=k)\n",
    "\n",
    "    # Computes mean reward for each arm\n",
    "    arm_true_means = np.dot(p_vectors, np.arange(R, dtype=np.float64))\n",
    "\n",
    "    # Compute the difference in means from the best arm\n",
    "    mu_star = arm_true_means.max()\n",
    "    deltas = mu_star - arm_true_means\n",
    "    \n",
    "    # Pre determines rewards  for each arm \n",
    "    arm_rewards = np.empty((k, T), dtype=np.int32)\n",
    "    for a in range(k):\n",
    "        arm_rewards[a, :] = weighted_choice(p_vectors[a], T)\n",
    "\n",
    "    return deltas, arm_rewards, arm_true_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def run_single_simulation(k, R, T, n_quantiles = n_quantiles, \n",
    "                                   t_quantiles = t_quantiles, \n",
    "                                   sqrts = sqrts):\n",
    "    \"\"\"Runs a single simulation of a multi-arm bandit with NUM_ALGO different\n",
    "    algorithms.\n",
    "\n",
    "    Args:\n",
    "        k (int): The number of arms.\n",
    "        R (int): The range of reward.\n",
    "        T (int): The number of rounds.\n",
    "        n_quantiles (np.array): A vector of quantiles from the normal \n",
    "        distribution.\n",
    "        t_quantiles (np.array): A matrix of quantiles from the t distribution. \n",
    "        Size MAX_DF x NUM_QUANTILES.\n",
    "        sqrts (np.array): A vector of square roots of the indices.\n",
    "\n",
    "    Returns:\n",
    "        np.matrix: A NUM_ALGO x T matrix containing the cumulative regrets for \n",
    "        Thompson sampling using a normal and t distribution.\n",
    "    \"\"\"\n",
    "    # Get the arm means and rewards\n",
    "    deltas, arm_rewards, arm_true_means = compute_rewards(k, R, T)\n",
    "    \n",
    "    # Pre-sets quantiles for each round and arm\n",
    "    arm_quantiles = np.random.randint(0, NUM_QUANTILES, (T, k))\n",
    "\n",
    "    # Gets the quantiles for the normal distribution of each round and arm\n",
    "    ts_n_quantiles = np.empty((T, k), dtype=n_quantiles.dtype)\n",
    "    for t in range(T):\n",
    "        for a in range(k):\n",
    "            ts_n_quantiles[t, a] = n_quantiles[arm_quantiles[t, a]]\n",
    "\n",
    "    # Initializes vectors to hold data during simulation\n",
    "    ts_t_quantiles = np.empty(k) # T distribution quantiles\n",
    "    arm_means = np.zeros((NUM_ALGO, k)) # Running arm means\n",
    "    arm_stds = np.zeros((NUM_ALGO, k)) +.000001 # Running arm standard deviations\n",
    "    n_t = np.zeros((NUM_ALGO, k), dtype=np.int32) # Number of arm pulls\n",
    "    R_t = np.zeros((NUM_ALGO, T), dtype=np.float32) # Cumulative regrets\n",
    "    regrets = np.empty(NUM_ALGO, dtype=np.float32) # Regret of current round\n",
    "    \n",
    "    # Starts the simulation\n",
    "    for t in range(T):\n",
    "\n",
    "        # Initializes array to hold actions for each algorithm in the round\n",
    "        actions = np.zeros(NUM_ALGO, dtype=np.int32)\n",
    "        \n",
    "        # Pull each arm twice\n",
    "        if t < 2 * k:\n",
    "            actions[0] = t % k\n",
    "            actions[1] = t % k\n",
    "        \n",
    "        # Then Thompson Sample\n",
    "        else:\n",
    "\n",
    "            # For each arm\n",
    "            for a in range(k):\n",
    "\n",
    "                # If it's been pulled less than MAX_DF, use a T distribution\n",
    "                if n_t[1, a] <= MAX_DF + 1:\n",
    "                    ts_t_quantiles[a] = (\n",
    "                        t_quantiles[n_t[1, a] - 2, arm_quantiles[t, a]])\n",
    "\n",
    "                # Otherwise use a normal approximation\n",
    "                else:\n",
    "                    ts_t_quantiles[a] = n_quantiles[arm_quantiles[t, a]]\n",
    "\n",
    "            # Scales the normal and t distribution algorithms with mean and std\n",
    "            adjusted_stds_n = arm_stds[0] / sqrts[n_t[0]]\n",
    "            adjusted_stds_t = arm_stds[1] / sqrts[n_t[1]]\n",
    "            \n",
    "            scaled_n_quantiles = (arm_means[0] \n",
    "                                  + ts_n_quantiles[t] * adjusted_stds_n)\n",
    "            scaled_t_quantiles = (arm_means[1] \n",
    "                                  + ts_t_quantiles * adjusted_stds_t)\n",
    "\n",
    "            # Choose the action with the highest sampled mean\n",
    "            actions[0] = np.argmax(scaled_n_quantiles)\n",
    "            actions[1] = np.argmax(scaled_t_quantiles)\n",
    "\n",
    "        # For each algorithm, update the mean and variance of the pulled arm\n",
    "        for i in range(NUM_ALGO):\n",
    "\n",
    "            # Store intermediate data\n",
    "            action = actions[i]\n",
    "            reward = arm_rewards[action, n_t[i, action]]\n",
    "            regrets[i] = deltas[action]\n",
    "            n_t[i, action] += 1\n",
    "            current_mean = arm_means[i, action]\n",
    "\n",
    "            # Intermediate calculations\n",
    "            current_var = arm_stds[i, action] ** 2\n",
    "            delta1 = reward - current_mean\n",
    "            new_mean = current_mean + (delta1 / n_t[i, action])\n",
    "            delta2 = reward - new_mean\n",
    "            new_var = current_var + (delta1 * delta2 / n_t[i, action])\n",
    "\n",
    "            # Update new mean and variance\n",
    "            arm_means[i, action] = new_mean\n",
    "            arm_stds[i, action] = np.sqrt(new_var)\n",
    "\n",
    "        # Update the sequence of cumulative regrets\n",
    "        if t > 0:\n",
    "            R_t[:, t] = R_t[:, t - 1] + regrets\n",
    "        else:\n",
    "            R_t[:, t] = regrets\n",
    "    \n",
    "    \n",
    "    return R_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def run_parallel_simulation(N, k, R, T, n_quantiles = n_quantiles, \n",
    "                                   t_quantiles = t_quantiles, \n",
    "                                   sqrts = sqrts):\n",
    "    \"\"\"Run N simulations of the multiarm bandits in parallel with Numba.\n",
    "\n",
    "    Args:\n",
    "        N (int): The number of simulations.\n",
    "        k (int): The number of arms.\n",
    "        R (int): The range of reward.\n",
    "        T (int): The number of rounds.\n",
    "        n_quantiles (np.array): A vector of quantiles from the normal \n",
    "        distribution.\n",
    "        t_quantiles (np.array): A matrix of quantiles from the t distribution. \n",
    "        Size MAX_DF x NUM_QUANTILES.\n",
    "        sqrts (np.array): A vector of square roots of the indices.\n",
    "\n",
    "    Returns:\n",
    "        np matrix: A NUM_ALGO x T x N matrix containing the cumulative regrets\n",
    "        of each algorithm over T rounds over N simulations\n",
    "    \"\"\"\n",
    "\n",
    "    results = np.empty((NUM_ALGO, T, N), dtype=np.float32)\n",
    "    for n in prange(N):\n",
    "        results[:, :, n] = run_single_simulation(\n",
    "                                k, R, T, n_quantiles = n_quantiles, \n",
    "                                   t_quantiles = t_quantiles, \n",
    "                                   sqrts = sqrts)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulations(N, k, R, T, n_quantiles = n_quantiles, \n",
    "                                   t_quantiles = t_quantiles, \n",
    "                                   sqrts = sqrts):\n",
    "    \"\"\"Runs N simulations of the mulitarm bandits. Splits simulations into\n",
    "    batches for better performance with high values of N and T.\n",
    "\n",
    "    Args:\n",
    "        N (int): The number of simulations.\n",
    "        k (int): The number of arms.\n",
    "        R (int): The range of reward.\n",
    "        T (int): The number of rounds.\n",
    "        n_quantiles (np.array): A vector of quantiles from the normal \n",
    "        distribution.\n",
    "        t_quantiles (np.array): A matrix of quantiles from the t distribution. \n",
    "        Size MAX_DF x NUM_QUANTILES.\n",
    "        sqrts (np.array): A vector of square roots of the indices.\n",
    "\n",
    "    Returns:\n",
    "        np matrix: A NUM_ALGO x T x N matrix containing the cumulative regrets\n",
    "        of each algorithm over T rounds over N simulations\n",
    "    \"\"\"\n",
    "\n",
    "    # Computes number of batches to run simulations in\n",
    "    batches = N * T  // LIMIT\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    if batches > 1:\n",
    "\n",
    "        # Initialize arrays to hold running mean and variances of the data\n",
    "        R_t_mean = np.zeros((NUM_ALGO, T))\n",
    "        R_t_m2 = np.zeros((NUM_ALGO, T))  \n",
    "\n",
    "        print(f\"\\nStarting {batches} batches.\\n\")\n",
    "\n",
    "        # For each batch\n",
    "        for i in range(batches):\n",
    "            \n",
    "            batch_start = time.time()\n",
    "            \n",
    "            # Run batch simulation and calculate mean and std for current batch\n",
    "            R_t_all = run_parallel_simulation(\n",
    "                        N // batches, k, R, T, n_quantiles = n_quantiles, \n",
    "                                   t_quantiles = t_quantiles, \n",
    "                                   sqrts = sqrts)\n",
    "            batch_mean = R_t_all.mean(axis=2)\n",
    "            batch_std = R_t_all.std(axis=2)\n",
    "            batch_variance = batch_std**2\n",
    "\n",
    "            # Update the combined mean and variance iteratively\n",
    "            delta = batch_mean - R_t_mean\n",
    "            R_t_mean += delta / (i + 1)  \n",
    "            R_t_m2 += batch_variance + delta**2 * i / (i + 1)  \n",
    "\n",
    "            # Print logging info\n",
    "            batch_end = time.time()\n",
    "            elapsed = round(batch_end - batch_start)\n",
    "            remaining = round(((elapsed * batches)-(elapsed * (i + 1))) / 60, 2)\n",
    "            print(f\"Batch {i + 1} complete, {elapsed} seconds.\")\n",
    "            print(f\"Remaining: {remaining} minutes.\\n\")\n",
    "\n",
    "        # Calculate the final standard deviation from the accumulated R_t_m2\n",
    "        R_t_std = np.sqrt(R_t_m2 / batches)\n",
    "\n",
    "    # If one batch is needed, run the simulation as normal\n",
    "    else:\n",
    "        R_t_all = run_parallel_simulation(\n",
    "                                N, k, R, T, n_quantiles = n_quantiles, \n",
    "                                   t_quantiles = t_quantiles, \n",
    "                                   sqrts = sqrts)\n",
    "        R_t_mean = R_t_all.mean(axis=2)\n",
    "        R_t_std = R_t_all.std(axis=2)\n",
    "\n",
    "    # Save data\n",
    "    np.save(f\"data/k{k}_R{R}_N{N}_T{T}_Means\", R_t_mean)\n",
    "    np.save(f\"data/k{k}_R{R}_N{N}_T{T}_Stds\", R_t_std)\n",
    "\n",
    "    # Print logging info\n",
    "    end = time.time()\n",
    "    elapsed = round((end - start) / 60, 2)\n",
    "    print(f\"Completion Time: {elapsed} minutes\\n\")\n",
    "\n",
    "    return R_t_mean, R_t_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def run_single_simulation_animation(k, R, T, n_quantiles = n_quantiles, \n",
    "                                   t_quantiles = t_quantiles, \n",
    "                                   sqrts = sqrts):\n",
    "    \"\"\"Runs a single simulation of a multi-arm bandit with NUM_ALGO different\n",
    "    algorithms.\n",
    "\n",
    "    Args:\n",
    "        k (int): The number of arms.\n",
    "        R (int): The range of reward.\n",
    "        T (int): The number of rounds.\n",
    "        n_quantiles (np.array): A vector of quantiles from the normal \n",
    "        distribution.\n",
    "        t_quantiles (np.array): A matrix of quantiles from the t distribution. \n",
    "        Size MAX_DF x NUM_QUANTILES.\n",
    "        sqrts (np.array): A vector of square roots of the indices.\n",
    "\n",
    "    Returns:\n",
    "        np.matrix: A NUM_ALGO x T matrix containing the cumulative regrets for \n",
    "        Thompson sampling using a normal and t distribution.\n",
    "    \"\"\"\n",
    "    all_arm_means = np.empty((NUM_ALGO, k, T))\n",
    "    all_arm_stds = np.empty((NUM_ALGO, k, T))\n",
    "\n",
    "    # Get the arm means and rewards\n",
    "    deltas, arm_rewards, arm_true_means = compute_rewards(k, R, T)\n",
    "    \n",
    "    # Pre-sets quantiles for each round and arm\n",
    "    arm_quantiles = np.random.randint(0, NUM_QUANTILES, (T, k))\n",
    "\n",
    "    # Gets the quantiles for the normal distribution of each round and arm\n",
    "    ts_n_quantiles = np.empty((T, k), dtype=n_quantiles.dtype)\n",
    "    for t in range(T):\n",
    "        for a in range(k):\n",
    "            ts_n_quantiles[t, a] = n_quantiles[arm_quantiles[t, a]]\n",
    "\n",
    "    # Initializes vectors to hold data during simulation\n",
    "    ts_t_quantiles = np.empty(k) # T distribution quantiles\n",
    "    arm_means = np.zeros((NUM_ALGO, k)) # Running arm means\n",
    "    arm_stds = np.zeros((NUM_ALGO, k)) +.001 # Running arm standard deviations\n",
    "    n_t = np.zeros((NUM_ALGO, k), dtype=np.int32) # Number of arm pulls\n",
    "    R_t = np.zeros((NUM_ALGO, T), dtype=np.float32) # Cumulative regrets\n",
    "    regrets = np.empty(NUM_ALGO, dtype=np.float32) # Regret of current round\n",
    "    \n",
    "    # Starts the simulation\n",
    "    for t in range(T):\n",
    "\n",
    "        # Initializes array to hold actions for each algorithm in the round\n",
    "        actions = np.zeros(NUM_ALGO, dtype=np.int32)\n",
    "        \n",
    "        # Pull each arm twice\n",
    "        if t < 2 * k:\n",
    "            actions[0] = t % k\n",
    "            actions[1] = t % k\n",
    "        \n",
    "        # Then Thompson Sample\n",
    "        else:\n",
    "\n",
    "            # For each arm\n",
    "            for a in range(k):\n",
    "\n",
    "                # If it's been pulled less than MAX_DF, use a T distribution\n",
    "                if n_t[1, a] <= MAX_DF + 1:\n",
    "                    ts_t_quantiles[a] = (\n",
    "                        t_quantiles[n_t[1, a] - 2, arm_quantiles[t, a]])\n",
    "\n",
    "                # Otherwise use a normal approximation\n",
    "                else:\n",
    "                    ts_t_quantiles[a] = n_quantiles[arm_quantiles[t, a]]\n",
    "\n",
    "            # Scales the normal and t distribution algorithms with mean and std\n",
    "            adjusted_stds_n = arm_stds[0] / sqrts[n_t[0]]\n",
    "            adjusted_stds_t = arm_stds[1] / sqrts[n_t[1]]\n",
    "            scaled_n_quantiles = (arm_means[0] \n",
    "                                  + ts_n_quantiles[t] * adjusted_stds_n)\n",
    "            scaled_t_quantiles = (arm_means[1] \n",
    "                                  + ts_t_quantiles * adjusted_stds_t)\n",
    "\n",
    "            # Choose the action with the highest sampled mean\n",
    "            actions[0] = np.argmax(scaled_n_quantiles)\n",
    "            actions[1] = np.argmax(scaled_t_quantiles)\n",
    "\n",
    "        # For each algorithm, update the mean and variance of the pulled arm\n",
    "        for i in range(NUM_ALGO):\n",
    "\n",
    "            # Store intermediate data\n",
    "            action = actions[i]\n",
    "            reward = arm_rewards[action, n_t[i, action]]\n",
    "            regrets[i] = deltas[action]\n",
    "            n_t[i, action] += 1\n",
    "            current_mean = arm_means[i, action]\n",
    "\n",
    "            # Intermediate calculations\n",
    "            current_var = arm_stds[i, action] ** 2\n",
    "            delta1 = reward - current_mean\n",
    "            new_mean = current_mean + (delta1 / n_t[i, action])\n",
    "            delta2 = reward - new_mean\n",
    "            new_var = current_var + (delta1 * delta2 / n_t[i, action])\n",
    "\n",
    "            # Update new mean and variance\n",
    "            arm_means[i, action] = new_mean\n",
    "            arm_stds[i, action] = np.sqrt(new_var)\n",
    "\n",
    "            all_arm_means[i,:,t] = arm_means[i,:]\n",
    "            all_arm_stds[i,:,t] = arm_stds[i,:] / sqrts[n_t[i, :]]\n",
    "\n",
    "        # Update the sequence of cumulative regrets\n",
    "        if t > 0:\n",
    "            R_t[:, t] = R_t[:, t - 1] + regrets\n",
    "        else:\n",
    "            R_t[:, t] = regrets\n",
    "\n",
    "    return R_t, all_arm_means, all_arm_stds, deltas, arm_true_means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Mean and Variance of Regret by Monte Carlo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs several monte carlo simulations for combinations of arms and ranges\n",
    "# Results are saved in the data folder\n",
    "# Can take several hours to run\n",
    "\n",
    "N = 10000\n",
    "T = 1000000\n",
    "ks = [3,4,5,6,7,8,9,10]\n",
    "Rs = [10,100,1000,10000]\n",
    "\n",
    "for k in ks:\n",
    "    for R in Rs:\n",
    "        run_simulations(N, k, R, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs a single monte carlo simulation\n",
    "# For high N and T, time-remaining info will be printed\n",
    "\n",
    "N = 1000\n",
    "T = 10000\n",
    "k = 3\n",
    "R = 10\n",
    "\n",
    "R_t_mean, R_t_std = run_simulations(N, k, R, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean Results\n",
    "fig_mean = go.Figure()\n",
    "x_vals = np.arange(1,T+1)\n",
    "\n",
    "fig_mean.add_trace(go.Scatter(\n",
    "    x=x_vals, y=R_t_mean[0], mode = 'lines', name = 'Normal Distribution'))\n",
    "\n",
    "fig_mean.add_trace(go.Scatter(\n",
    "    x=x_vals, y=R_t_mean[1], mode = 'lines', name = 'T Distribution'))\n",
    "\n",
    "fig_mean.update_layout(\n",
    "    title=f\"Mean Regret Across {N} Trials\",\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=\"Round\",\n",
    "    yaxis_title=\"Mean Regret\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    template=\"plotly\",\n",
    "    legend=dict(\n",
    "        x=0.72,\n",
    "        y=0.07,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.25)\" \n",
    "    )\n",
    ")\n",
    "fig_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Variance Results\n",
    "fig_var = go.Figure()\n",
    "x_vals = np.arange(1,T+1)\n",
    "\n",
    "fig_var.add_trace(go.Scatter(\n",
    "    x=x_vals, y=R_t_std[0], mode = 'lines', name = 'Normal Distribution'))\n",
    "\n",
    "fig_var.add_trace(go.Scatter(\n",
    "    x=x_vals, y=R_t_std[1], mode = 'lines', name = 'T Distribution'))\n",
    "\n",
    "fig_var.update_layout(\n",
    "    title=f\"Variance of Regret across {N} Trials\",\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=\"Round\",\n",
    "    yaxis_title=\"Regret Variance\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    template=\"plotly\",\n",
    "    legend=dict(\n",
    "        x=0.72,\n",
    "        y=0.07,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.25)\" \n",
    "    )\n",
    ")\n",
    "fig_var.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a single simulation\n",
    "N = 1000\n",
    "T = 10000\n",
    "k = 3\n",
    "R = 10\n",
    "\n",
    "R_t = run_single_simulation(k, R, T)\n",
    "\n",
    "# Plot Results\n",
    "fig_mean = go.Figure()\n",
    "x_vals = np.arange(1,T+1)\n",
    "\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t[0], mode = 'lines', name = 'Normal Distribution',showlegend = True))\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t[1], mode = 'lines', name = 'T Distribution', showlegend = True))\n",
    "\n",
    "fig_mean.update_layout(\n",
    "    title=\"Regret of Thompson Sampling with Normal Posterior\",\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=\"Round\",\n",
    "    yaxis_title=\"Regret Mean\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    template=\"plotly\",\n",
    "    legend=dict(\n",
    "        x=0.72,\n",
    "        y=0.07,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.25)\" \n",
    "    )\n",
    ")\n",
    "\n",
    "fig_mean.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Data for Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs and displays the results of the single trial\n",
    "T = 10000\n",
    "k = 3\n",
    "R = 10\n",
    "\n",
    "# Runs a single simulation to be animated\n",
    "R_t, means, stds, deltas, arm_means = run_single_simulation_animation(k, R, T)\n",
    "\n",
    "# Plot Results\n",
    "fig_mean = go.Figure()\n",
    "x_vals = np.arange(1,T+1)\n",
    "\n",
    "fig_mean.add_trace(go.Scatter(\n",
    "    x=x_vals, y=R_t[0], mode = 'lines', name = 'Normal Distribution'))\n",
    "\n",
    "fig_mean.add_trace(go.Scatter(\n",
    "    x=x_vals, y=R_t[1], mode = 'lines', name = 'T Distribution'))\n",
    "\n",
    "fig_mean.update_layout(\n",
    "    title=\"Mean Regret of Thompson Sampling Algorithms\",\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=\"Round\",\n",
    "    yaxis_title=\"Regret Mean\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    template=\"plotly\",\n",
    "    legend=dict(\n",
    "        x=0.72,\n",
    "        y=0.07,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.25)\" \n",
    "    )\n",
    ")\n",
    "fig_mean.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Animate the Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 11, 1000)\n",
    "fig = go.Figure()\n",
    "\n",
    "n_mus = means[0]\n",
    "n_stds = stds[0]\n",
    "\n",
    "colors = plotly.colors.DEFAULT_PLOTLY_COLORS[:3]\n",
    "\n",
    "# Loop over reward vector to calculate distributions up to that point\n",
    "frames = []\n",
    "for t in range(5, 500):\n",
    "    \n",
    "    # Create traces for each distribution at the current time step\n",
    "    traces = []\n",
    "\n",
    "    for arm, arm_mean, color in zip([1, 2, 3], arm_means, colors):\n",
    "        dashed_line = go.Scatter(\n",
    "        x=[arm_mean, arm_mean],\n",
    "        y=[0, .25],  # Extend the line over a reasonable y-range (adjust if needed)\n",
    "        mode='lines',\n",
    "        line=dict(dash='dash', width=2, color = color),\n",
    "        name=f'Arm {arm} True Mean',\n",
    "        showlegend=False\n",
    "        )\n",
    "        traces.append(dashed_line)\n",
    "\n",
    "    for mu, std, arm, color in zip(n_mus[:, t], n_stds[:, t], [1, 2, 3], colors):\n",
    "        y = (1 / (std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / std) ** 2)\n",
    "        trace = go.Scatter(x=x, y=y,line=dict(color=color), \n",
    "                           mode='lines', name=f'Arm {arm} N({mu:.2f}, {std**2:.2f})')\n",
    "        traces.append(trace)\n",
    "    \n",
    "    # Add an annotation to display the current round\n",
    "    annotation = go.layout.Annotation(\n",
    "        text=f\"Round: {t+1}\",\n",
    "        x=0.5, y=1.1, xref=\"paper\", yref=\"paper\", showarrow=False,\n",
    "        font=dict(size=16)\n",
    "    )\n",
    "\n",
    "    # Append frame with current traces\n",
    "    frames.append(go.Frame(data=traces, name=str(t), layout=go.Layout(annotations=[annotation])))\n",
    "\n",
    "# Add traces for the first frame\n",
    "for trace in frames[0].data:\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "# Add the annotation for the first frame\n",
    "initial_annotation = go.layout.Annotation(\n",
    "    text=f\"Round: 6\",  # Adjust to match the first round value\n",
    "    x=0.5, y=1.1, xref=\"paper\", yref=\"paper\", showarrow=False,\n",
    "    font=dict(size=16)\n",
    ")\n",
    "\n",
    "# Configure the animation settings\n",
    "fig.update(frames=frames)\n",
    "fig.update_layout(\n",
    "    annotations=[initial_annotation],\n",
    "    title=\"Arm Mean Distributions - Normal\",\n",
    "    title_x= 0.4,\n",
    "    xaxis_title=\"Mean Reward\",\n",
    "    yaxis_title=\"Density\",\n",
    "    legend=dict(\n",
    "        x=0.75,\n",
    "        y=0.97,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.25)\"),\n",
    "    updatemenus=[dict(type=\"buttons\", showactive=False,\n",
    "                      buttons=[\n",
    "                          dict(label=\"Play\",\n",
    "                               method=\"animate\",\n",
    "                               args=[None, {\"frame\": {\"duration\": 30, \"redraw\": True},\n",
    "                                            \"fromcurrent\": True}]),\n",
    "                          dict(label=\"Stop\",\n",
    "                               method=\"animate\",\n",
    "                               args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "                                              \"mode\": \"immediate\",\n",
    "                                              \"transition\": {\"duration\": 0}}])\n",
    "                      ])]\n",
    ")\n",
    "\n",
    "# Show the animated plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Animate the T distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a matrix to track the number of pulls\n",
    "dfs = np.zeros_like(means[1])\n",
    "\n",
    "# Iterate over columns to compute pulls\n",
    "for i in range(1, means[1].shape[1]):\n",
    "    # Compare the current column with the previous column\n",
    "    dfs[:, i] = dfs[:, i - 1] + (means[1][:, i] != means[1][:, i - 1])\n",
    "\n",
    "x = np.linspace(0, 11, 1000)\n",
    "fig = go.Figure()\n",
    "\n",
    "n_mus = means[1]\n",
    "n_stds = stds[1]\n",
    "\n",
    "colors = plotly.colors.DEFAULT_PLOTLY_COLORS[:3]\n",
    "\n",
    "def t_distribution_pdf(x, mu, sigma, df):\n",
    "    # Compute the scaling factor\n",
    "    scale_factor = gamma((df + 1) / 2) / (np.sqrt(df * np.pi) * sigma * gamma(df / 2))\n",
    "    # Compute the PDF\n",
    "    y = scale_factor * (1 + ((x - mu) ** 2) / (df * sigma ** 2)) ** (-(df + 1) / 2)\n",
    "    return y\n",
    "\n",
    "# Loop over reward vector to calculate distributions up to that point\n",
    "frames = []\n",
    "for t in range(5, 500):\n",
    "    \n",
    "    # Create traces for each distribution at the current time step\n",
    "    traces = []\n",
    "\n",
    "    for arm, arm_mean, color in zip([1, 2, 3], arm_means, colors):\n",
    "        dashed_line = go.Scatter(\n",
    "        x=[arm_mean, arm_mean],\n",
    "        y=[0, .25],  # Extend the line over a reasonable y-range (adjust if needed)\n",
    "        mode='lines',\n",
    "        line=dict(dash='dash', width=2, color = color),\n",
    "        name=f'Arm {arm} True Mean',\n",
    "        showlegend=False\n",
    "        )\n",
    "        traces.append(dashed_line)\n",
    "\n",
    "    for mu, std, arm, df, color in zip(n_mus[:, t], n_stds[:, t], [1, 2, 3], dfs[:,t], colors):\n",
    "        y = t_distribution_pdf(x,mu,std,df)\n",
    "        trace = go.Scatter(x=x, y=y,line=dict(color=color), \n",
    "                           mode='lines', name=f'Arm {arm} N({mu:.2f}, {std**2:.2f})')\n",
    "        traces.append(trace)\n",
    "    \n",
    "    # Add an annotation to display the current round\n",
    "    annotation = go.layout.Annotation(\n",
    "        text=f\"Round: {t}\",\n",
    "        x=0.5, y=1.1, xref=\"paper\", yref=\"paper\", showarrow=False,\n",
    "        font=dict(size=16)\n",
    "    )\n",
    "\n",
    "    # Append frame with current traces\n",
    "    frames.append(go.Frame(data=traces, name=str(t), layout=go.Layout(annotations=[annotation])))\n",
    "\n",
    "# Add traces for the first frame\n",
    "for trace in frames[0].data:\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "# Add the annotation for the first frame\n",
    "initial_annotation = go.layout.Annotation(\n",
    "    text=f\"Round: 6\",  # Adjust to match the first round value\n",
    "    x=0.5, y=1.1, xref=\"paper\", yref=\"paper\", showarrow=False,\n",
    "    font=dict(size=16)\n",
    ")\n",
    "\n",
    "# Configure the animation settings\n",
    "fig.update(frames=frames)\n",
    "fig.update_layout(\n",
    "    annotations=[initial_annotation],\n",
    "    title=\"Arm Mean Distributions - t\",\n",
    "    title_x= 0.4,\n",
    "    xaxis_title=\"Mean Reward\",\n",
    "    yaxis_title=\"Density\",\n",
    "    legend=dict(\n",
    "        x=0.75,\n",
    "        y=0.97,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.25)\"),\n",
    "    updatemenus=[dict(type=\"buttons\", showactive=False,\n",
    "                      buttons=[\n",
    "                          dict(label=\"Play\",\n",
    "                               method=\"animate\",\n",
    "                               args=[None, {\"frame\": {\"duration\": 30, \"redraw\": True},\n",
    "                                            \"fromcurrent\": True}]),\n",
    "                          dict(label=\"Stop\",\n",
    "                               method=\"animate\",\n",
    "                               args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "                                              \"mode\": \"immediate\",\n",
    "                                              \"transition\": {\"duration\": 0}}])\n",
    "                      ])]\n",
    ")\n",
    "\n",
    "# Show the animated plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc190",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
