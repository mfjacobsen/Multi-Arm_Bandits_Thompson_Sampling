{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from numba import njit, prange\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_T = 10000000\n",
    "MAX_DF = 10000\n",
    "NUM_QUANTILES = 99999\n",
    "LIMIT = 100000000\n",
    "\n",
    "# Precomputed values\n",
    "sqrts = np.sqrt(np.arange(MAX_T))\n",
    "\n",
    "# Load or compute sqare roots and quantiles\n",
    "sqrts_path = f'tables/first_{MAX_T}_sqrts.npy'\n",
    "n_quantiles_path = f'tables/n_quantiles_q{NUM_QUANTILES}.npy'\n",
    "t_quantiles_path = f'tables/t_quantiles_df{MAX_DF}_q{NUM_QUANTILES}.npy'\n",
    "\n",
    "# Ensure the 'data' directory exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Computes square roots\n",
    "if not Path(sqrts_path).exists():\n",
    "    sqrts = np.sqrt(np.arange(MAX_T))\n",
    "    np.save(sqrts_path, sqrts)\n",
    "\n",
    "# Computes normal and t distribution quantiles\n",
    "if not Path(n_quantiles_path).exists() or not Path(t_quantiles_path).exists():\n",
    "    \n",
    "    # Possible quantiles for Thompson sampling\n",
    "    quantiles = np.linspace(0.00001, 0.99999, NUM_QUANTILES).round(5)\n",
    "\n",
    "    # Computes quantiles for normal and t distributions up to MAX_DF\n",
    "    # after which normal approximation is used\n",
    "    n_quantiles = stats.norm().ppf(quantiles)\n",
    "    t_quantiles = np.array(\n",
    "        [stats.t(df).ppf(quantiles) for df in range(1, MAX_DF + 1)], \n",
    "                  dtype=np.float32)\n",
    "\n",
    "    # Saves the quantile tables\n",
    "    np.save(n_quantiles_path, n_quantiles)\n",
    "    np.save(t_quantiles_path, t_quantiles)\n",
    "\n",
    "# Loads quantile tables and square roots\n",
    "n_quantiles = np.load(n_quantiles_path)\n",
    "t_quantiles = np.load(t_quantiles_path)\n",
    "sqrts = np.load(sqrts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A numba implementation for np.random.choice using the CDF of probabilites\n",
    "@njit\n",
    "def weighted_choice(probabilities, size):\n",
    "    \"\"\"A numba implementation for np.random.choice using the CDF of probabilites\n",
    "\n",
    "    Args:\n",
    "        probabilities (np.array): An array of probabilities corresponding to the\n",
    "         probability of choosing that integer index. Should sum to 1.\n",
    "        size (int): The number of samples to choose from the probability vector\n",
    "\n",
    "    Returns:\n",
    "        np.array: A vector of length (size) of integers chosen with the given \n",
    "        probabilites\n",
    "    \"\"\"\n",
    "    cumulative_sum = np.cumsum(probabilities)\n",
    "    choices = np.searchsorted(cumulative_sum, np.random.rand(size))\n",
    "    return choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-determines rewards for each arm \n",
    "@njit\n",
    "def compute_rewards(k, R, T):\n",
    "    \"\"\"Pre-computes rewards for each arm of the bandit at round t\n",
    "\n",
    "    Args:\n",
    "        k (int): The number of bandit arms.\n",
    "        R (int): The range of reward.\n",
    "        T (int): The number of rounds in the game.\n",
    "\n",
    "    Returns:\n",
    "        numpy vector: deltas : A length k vector containg the difference in mean \n",
    "        of each arm from the arm wih the highest mean.\n",
    "        numpy matrix: arm_rewards: A k x T matrix that holds the rewards for \n",
    "        arm k at round T\n",
    "    \"\"\"\n",
    "\n",
    "    # Randomizes reward probability for each arm\n",
    "    p_vectors = np.random.dirichlet(np.ones(R), size=k)\n",
    "\n",
    "    # Computes mean reward for each arm\n",
    "    arm_true_means = np.dot(p_vectors, np.arange(R, dtype=np.float64))\n",
    "\n",
    "    # Compute the difference in means from the best arm\n",
    "    mu_star = arm_true_means.max()\n",
    "    deltas = mu_star - arm_true_means\n",
    "    \n",
    "    # Pre determines rewards  for each arm \n",
    "    arm_rewards = np.empty((k, T), dtype=np.int32)\n",
    "    for a in range(k):\n",
    "        arm_rewards[a, :] = weighted_choice(p_vectors[a], T)\n",
    "\n",
    "    return deltas, arm_rewards, arm_true_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def run_single_simulation(k, R, T, explore_lens,\n",
    "                                   n_quantiles = n_quantiles, \n",
    "                                   t_quantiles = t_quantiles, \n",
    "                                   sqrts = sqrts):\n",
    "    \"\"\"Runs a single simulation of a multi-arm bandit with NUM_ALGO different\n",
    "    algorithms.\n",
    "\n",
    "    Args:\n",
    "        k (int): The number of arms.\n",
    "        R (int): The range of reward.\n",
    "        T (int): The number of rounds.\n",
    "        n_quantiles (np.array): A vector of quantiles from the normal \n",
    "        distribution.\n",
    "        t_quantiles (np.array): A matrix of quantiles from the t distribution. \n",
    "        Size MAX_DF x NUM_QUANTILES.\n",
    "        sqrts (np.array): A vector of square roots of the indices.\n",
    "\n",
    "    Returns:\n",
    "        np.matrix: A NUM_ALGO x T matrix containing the cumulative regrets for \n",
    "        Thompson sampling using a normal and t distribution.\n",
    "    \"\"\"\n",
    "    # Length of explorations\n",
    "    NUM_ALGO = explore_lens.size\n",
    "\n",
    "    # Get the arm means and rewards\n",
    "    deltas, arm_rewards, arm_true_means = compute_rewards(k, R, T)\n",
    "    \n",
    "    # Pre-sets quantiles for each round and arm\n",
    "    arm_quantiles = np.random.randint(0, NUM_QUANTILES, (T, k))\n",
    "\n",
    "    # Gets the quantiles for the normal distribution of each round and arm\n",
    "    ts_n_quantiles = np.empty((T, k), dtype=n_quantiles.dtype)\n",
    "    for t in range(T):\n",
    "        for a in range(k):\n",
    "            ts_n_quantiles[t, a] = n_quantiles[arm_quantiles[t, a]]\n",
    "\n",
    "    # Initializes vectors to hold data during simulation\n",
    "    ts_quantiles = np.empty(k, dtype=np.float32) # Thompson Sampled quantiles\n",
    "    arm_means = np.zeros((NUM_ALGO, k)) # Running arm means\n",
    "    arm_stds = np.zeros((NUM_ALGO, k)) +.000001 # Running arm standard deviations\n",
    "    n_t = np.zeros((NUM_ALGO, k), dtype=np.int32) # Number of arm pulls\n",
    "    R_t = np.zeros((NUM_ALGO, T), dtype=np.float32) # Cumulative regrets\n",
    "    regrets = np.empty(NUM_ALGO, dtype=np.float32) # Regret of current round\n",
    "\n",
    "    explore_idxs = [i for i in range(NUM_ALGO)]\n",
    "    ts_idxs = []\n",
    "\n",
    "    # Starts the simulation\n",
    "    for t in range(T):\n",
    "\n",
    "        # Initializes array to hold actions for each algorithm in the round\n",
    "        actions = np.zeros(NUM_ALGO, dtype=np.int32)\n",
    "        \n",
    "        # For algorithms still in exploration phase, explore\n",
    "        for idx in explore_idxs.copy():\n",
    "\n",
    "            if t < explore_lens[idx] * k:\n",
    "                actions[idx] = t % k\n",
    "\n",
    "            elif t == explore_lens[idx] * k:\n",
    "                ts_idxs.append(explore_idxs[0])\n",
    "                explore_idxs = explore_idxs[1:]\n",
    "        \n",
    "        # Then Thompson Sample\n",
    "        for idx in ts_idxs:\n",
    "        \n",
    "            if idx == 1 or idx == 3:\n",
    "                # For each arm\n",
    "                for a in range(k):\n",
    "\n",
    "                    # If it's been pulled less than MAX_DF, use a T distribution\n",
    "                    if n_t[1, a] <= MAX_DF + 1:\n",
    "                        ts_quantiles[a] = (\n",
    "                            t_quantiles[n_t[1, a] - 2, arm_quantiles[t, a]])\n",
    "\n",
    "                    # Otherwise use a normal approximation\n",
    "                    else:\n",
    "                        ts_quantiles[a] = ts_n_quantiles[t,a]\n",
    "\n",
    "            else:\n",
    "                ts_quantiles = ts_n_quantiles[t,:]\n",
    "\n",
    "\n",
    "            # Scales the normal and t distribution algorithms with mean and std\n",
    "            adjusted_stds = arm_stds[idx] / sqrts[n_t[idx]]\n",
    "\n",
    "            scaled_quantiles = (arm_means[idx] \n",
    "                                  + ts_quantiles * adjusted_stds)\n",
    "\n",
    "            # Choose the action with the highest sampled mean\n",
    "            actions[idx] = np.argmax(scaled_quantiles)\n",
    "\n",
    "        # For each algorithm, update the mean and variance of the pulled arm\n",
    "        for i in range(NUM_ALGO):\n",
    "\n",
    "            # Store intermediate data\n",
    "            action = actions[i]\n",
    "            reward = arm_rewards[action, n_t[i, action]]\n",
    "            regrets[i] = deltas[action]\n",
    "            n_t[i, action] += 1\n",
    "            current_mean = arm_means[i, action]\n",
    "\n",
    "            # Intermediate calculations\n",
    "            current_var = arm_stds[i, action] ** 2\n",
    "            delta1 = reward - current_mean\n",
    "            new_mean = current_mean + (delta1 / n_t[i, action])\n",
    "            delta2 = reward - new_mean\n",
    "            new_var = current_var + (delta1 * delta2 / n_t[i, action])\n",
    "\n",
    "            # Update new mean and variance\n",
    "            arm_means[i, action] = new_mean\n",
    "            arm_stds[i, action] = np.sqrt(new_var)\n",
    "\n",
    "        # Update the sequence of cumulative regrets\n",
    "        if t > 0:\n",
    "            R_t[:, t] = R_t[:, t - 1] + regrets\n",
    "        else:\n",
    "            R_t[:, t] = regrets\n",
    "    \n",
    "    \n",
    "    return R_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def run_parallel_simulation(N, k, R, T, explore_lens,\n",
    "                            n_quantiles = n_quantiles, \n",
    "                            t_quantiles = t_quantiles, \n",
    "                            sqrts = sqrts):\n",
    "    \"\"\"Run N simulations of the multiarm bandits in parallel with Numba.\n",
    "\n",
    "    Args:\n",
    "        N (int): The number of simulations.\n",
    "        k (int): The number of arms.\n",
    "        R (int): The range of reward.\n",
    "        T (int): The number of rounds.\n",
    "        n_quantiles (np.array): A vector of quantiles from the normal \n",
    "        distribution.\n",
    "        t_quantiles (np.array): A matrix of quantiles from the t distribution. \n",
    "        Size MAX_DF x NUM_QUANTILES.\n",
    "        sqrts (np.array): A vector of square roots of the indices.\n",
    "\n",
    "    Returns:\n",
    "        np matrix: A NUM_ALGO x T x N matrix containing the cumulative regrets\n",
    "        of each algorithm over T rounds over N simulations\n",
    "    \"\"\"\n",
    "    NUM_ALGO = explore_lens.size\n",
    "    results = np.empty((NUM_ALGO, T, N), dtype=np.float32)\n",
    "    for n in prange(N):\n",
    "        results[:, :, n] = run_single_simulation(\n",
    "                                k, R, T, explore_lens,\n",
    "                                n_quantiles = n_quantiles, \n",
    "                                t_quantiles = t_quantiles, \n",
    "                                sqrts = sqrts)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulations(N, k, R, T, explore_lens,\n",
    "                    n_quantiles = n_quantiles, \n",
    "                    t_quantiles = t_quantiles, \n",
    "                    sqrts = sqrts):\n",
    "    \"\"\"Runs N simulations of the mulitarm bandits. Splits simulations into\n",
    "    batches for better performance with high values of N and T.\n",
    "\n",
    "    Args:\n",
    "        N (int): The number of simulations.\n",
    "        k (int): The number of arms.\n",
    "        R (int): The range of reward.\n",
    "        T (int): The number of rounds.\n",
    "        n_quantiles (np.array): A vector of quantiles from the normal \n",
    "        distribution.\n",
    "        t_quantiles (np.array): A matrix of quantiles from the t distribution. \n",
    "        Size MAX_DF x NUM_QUANTILES.\n",
    "        sqrts (np.array): A vector of square roots of the indices.\n",
    "\n",
    "    Returns:\n",
    "        np matrix: A NUM_ALGO x T x N matrix containing the cumulative regrets\n",
    "        of each algorithm over T rounds over N simulations\n",
    "    \"\"\"\n",
    "    NUM_ALGO = explore_lens.size\n",
    "\n",
    "    # Computes number of batches to run simulations in\n",
    "    batches = N * T  // LIMIT\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    if batches > 1:\n",
    "\n",
    "        # Initialize arrays to hold running mean and variances of the data\n",
    "        R_t_mean = np.zeros((NUM_ALGO, T))\n",
    "        R_t_m2 = np.zeros((NUM_ALGO, T))  \n",
    "\n",
    "        print(f\"\\nStarting {batches} batches.\\n\")\n",
    "\n",
    "        # For each batch\n",
    "        for i in range(batches):\n",
    "            \n",
    "            batch_start = time.time()\n",
    "            \n",
    "            # Run batch simulation and calculate mean and std for current batch\n",
    "            R_t_all = run_parallel_simulation(\n",
    "                        N // batches, k, R, T, explore_lens,\n",
    "                                n_quantiles = n_quantiles, \n",
    "                                t_quantiles = t_quantiles, \n",
    "                                sqrts = sqrts)\n",
    "            batch_mean = R_t_all.mean(axis=2)\n",
    "            batch_std = R_t_all.std(axis=2)\n",
    "            batch_variance = batch_std**2\n",
    "\n",
    "            # Update the combined mean and variance iteratively\n",
    "            delta = batch_mean - R_t_mean\n",
    "            R_t_mean += delta / (i + 1)  \n",
    "            R_t_m2 += batch_variance + delta**2 * i / (i + 1)  \n",
    "\n",
    "            # Print logging info\n",
    "            batch_end = time.time()\n",
    "            elapsed = round(batch_end - batch_start)\n",
    "            remaining = round(((elapsed * batches)-(elapsed * (i + 1))) / 60, 2)\n",
    "            print(f\"Batch {i + 1} complete, {elapsed} seconds.\")\n",
    "            print(f\"Remaining: {remaining} minutes.\\n\")\n",
    "\n",
    "        # Calculate the final standard deviation from the accumulated R_t_m2\n",
    "        R_t_std = np.sqrt(R_t_m2 / batches)\n",
    "\n",
    "    # If one batch is needed, run the simulation as normal\n",
    "    else:\n",
    "        R_t_all = run_parallel_simulation(\n",
    "                                N, k, R, T, explore_lens,\n",
    "                                n_quantiles = n_quantiles, \n",
    "                                t_quantiles = t_quantiles, \n",
    "                                sqrts = sqrts)\n",
    "        R_t_mean = R_t_all.mean(axis=2)\n",
    "        R_t_std = R_t_all.std(axis=2)\n",
    "\n",
    "    # Save data\n",
    "    np.save(f\"data/k{k}_R{R}_N{N}_T{T}_Means\", R_t_mean)\n",
    "    np.save(f\"data/k{k}_R{R}_N{N}_T{T}_Stds\", R_t_std)\n",
    "\n",
    "    # Print logging info\n",
    "    end = time.time()\n",
    "    elapsed = round((end - start) / 60, 2)\n",
    "    print(f\"Completion Time: {elapsed} minutes\\n\")\n",
    "\n",
    "    return R_t_mean, R_t_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "T = 1000000\n",
    "explore_lens = np.array([2,2,15,30])\n",
    "ks = [3,4,5,6,7,8]\n",
    "Rs = [10,100,1000]\n",
    "\n",
    "for k in ks:\n",
    "    for R in Rs:\n",
    "        run_simulations(N, k, R, T, explore_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "T = 10000\n",
    "k = 3\n",
    "R = 10\n",
    "explore_lens = np.array([2,2,15,30])\n",
    "\n",
    "R_t_mean, R_t_std = run_simulations(N, k, R, T, explore_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Results\n",
    "fig_mean = go.Figure()\n",
    "x_vals = np.arange(1,T+1)\n",
    "\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t_mean[0], mode = 'lines', name = 'Normal Distribution'))\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t_mean[1], mode = 'lines', name = 'T Distribution'))\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t_mean[2], mode = 'lines', name = 'Explore 15'))\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t_mean[3], mode = 'lines', name = 'Explore 30'))\n",
    "\n",
    "fig_mean.update_layout(\n",
    "    title=f\"Mean Regret Across {N} Trials\",\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=\"Round\",\n",
    "    yaxis_title=\"Mean Regret\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    template=\"plotly\",\n",
    "    legend=dict(\n",
    "        x=0.72,\n",
    "        y=0.07,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.25)\" \n",
    "    )\n",
    ")\n",
    "fig_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_var = go.Figure()\n",
    "x_vals = np.arange(1,T+1)\n",
    "\n",
    "fig_var.add_trace(go.Scatter(x=x_vals, y=R_t_std[0], mode = 'lines', name = 'Normal Distribution'))\n",
    "fig_var.add_trace(go.Scatter(x=x_vals, y=R_t_std[1], mode = 'lines', name = 'T Distribution'))\n",
    "fig_var.add_trace(go.Scatter(x=x_vals, y=R_t_std[2], mode = 'lines', name = 'Explore 15'))\n",
    "fig_var.add_trace(go.Scatter(x=x_vals, y=R_t_std[3], mode = 'lines', name = 'Explore 30'))\n",
    "\n",
    "fig_var.update_layout(\n",
    "    title=f\"Variance of Regret across {N} Trials\",\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=\"Round\",\n",
    "    yaxis_title=\"Regret Variance\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    template=\"plotly\",\n",
    "    legend=dict(\n",
    "        x=0.72,\n",
    "        y=0.07,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.25)\" \n",
    "    )\n",
    ")\n",
    "fig_var.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "R = 10\n",
    "T = 10000\n",
    "\n",
    "R_t = run_single_simulation(k, R, T, n_quantiles, t_quantiles, sqrts)\n",
    "\n",
    "# Plot Results\n",
    "fig_mean = go.Figure()\n",
    "x_vals = np.arange(1,T+1)\n",
    "\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t[0], mode = 'lines', name = 'Normal Distribution',showlegend = True))\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t[1], mode = 'lines', name = 'T Distribution', showlegend = True))\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t[2], mode = 'lines', name = 'Explore 15',showlegend = True))\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t[3], mode = 'lines', name = 'Explore 30', showlegend = True))\n",
    "\n",
    "\n",
    "fig_mean.update_layout(\n",
    "    title=\"Regret of Thompson Sampling with Normal Posterior\",\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=\"Round\",\n",
    "    yaxis_title=\"Cumulative Regret\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    template=\"plotly\",\n",
    "    legend=dict(\n",
    "        x=0.72,\n",
    "        y=0.07,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.25)\" \n",
    "    )\n",
    ")\n",
    "\n",
    "fig_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads and displays previously stored data\n",
    "k = 3\n",
    "R = 10\n",
    "N = 10000\n",
    "T = 1000000\n",
    "\n",
    "R_t_mean = np.load(f\"data/k{k}_R{R}_N{N}_T{T}_Means.npy\")\n",
    "R_t_std = np.load(f\"data/k{k}_R{R}_N{N}_T{T}_Stds.npy\")\n",
    "\n",
    "# Plot Results\n",
    "fig_mean = go.Figure()\n",
    "x_vals = np.arange(1,T+1)\n",
    "\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t_mean[0], mode = 'lines', name = 'Normal Distribution'))\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t_mean[1], mode = 'lines', name = 'T Distribution'))\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t_mean[2], mode = 'lines', name = 'Explore 15, Normal'))\n",
    "fig_mean.add_trace(go.Scatter(x=x_vals, y=R_t_mean[3], mode = 'lines', name = 'Explore 30, Normal'))\n",
    "\n",
    "fig_mean.update_layout(\n",
    "    title=f\"Mean Regret Across {N} Trials\",\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=\"Round\",\n",
    "    yaxis_title=\"Mean Regret\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    template=\"plotly\",\n",
    "    legend=dict(\n",
    "        x=0.01,\n",
    "        y=0.97,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.25)\" \n",
    "    )\n",
    ")\n",
    "\n",
    "fig_mean.add_annotation(\n",
    "    text=f\"k = {k} ; R = {R}\",\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    x=0.5, y=1.15,  # Position the note\n",
    "    showarrow=False,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "fig_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_var = go.Figure()\n",
    "x_vals = np.arange(1,T+1)\n",
    "\n",
    "fig_var.add_trace(go.Scatter(x=x_vals, y=R_t_std[0], mode = 'lines', name = 'Normal Distribution'))\n",
    "fig_var.add_trace(go.Scatter(x=x_vals, y=R_t_std[1], mode = 'lines', name = 'T Distribution'))\n",
    "fig_var.add_trace(go.Scatter(x=x_vals, y=R_t_std[2], mode = 'lines', name = 'Explore 15, Normal'))\n",
    "fig_var.add_trace(go.Scatter(x=x_vals, y=R_t_std[3], mode = 'lines', name = 'Explore 30, Normal'))\n",
    "\n",
    "fig_var.update_layout(\n",
    "    title=f\"Variance of Regret Across {N} Trials\",\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=\"Round\",\n",
    "    yaxis_title=\"Regret Variance\",\n",
    "    width=800,\n",
    "    height=400,\n",
    "    template=\"plotly\",\n",
    "    legend=dict(\n",
    "        x=0.01,\n",
    "        y=0.97,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.25)\" \n",
    "    )\n",
    ")\n",
    "\n",
    "fig_var.add_annotation(\n",
    "    text=f\"k = {k} ; R = {R}\",\n",
    "    xref=\"paper\", yref=\"paper\",\n",
    "    x=0.5, y=1.15,  # Position the note\n",
    "    showarrow=False,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "fig_var.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc190",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
